{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python to process data that's too large to fit into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I generated some sample data into a database using [Mockaroo](https://www.mockaroo.com/) that includes bg values for different users throughout the day. \n",
    "\n",
    "Although the data is only 600 rows, I'll use this opportunity to process it chunkwise in python as if it were data that could not fit in memory. Let's get a quick look at the data first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database file with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bgVal</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>15:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>19:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>347</td>\n",
       "      <td>8:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bgVal   time\n",
       "0   1    230  15:52\n",
       "1   2     80  19:22\n",
       "2   3    347   8:13"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "#Connect to our database\n",
    "con= sqlite3.connect('bgTable.db')\n",
    "\n",
    "#Read the first few lines from our table\n",
    "table0= pd.read_sql_query('SELECT * FROM bgTable LIMIT 3', con)\n",
    "table0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can see our table, we'll need to define the query that we'd like to apply to the table. We want to add a new column to our data that labels our row based on the bgValues value. It can fall into three groups: 1) Less than or equal to 80 2) between 81 and 250 and 3) Greater than 250. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#binItems query has nested 'case when' statements to create a new\n",
    "#column called 'bin' that includes a label for each row depending\n",
    "#on the value of the bgVal column\n",
    "binItems= '''\n",
    "SELECT *, \n",
    "CASE WHEN bgVal <=80 THEN 'below'  \n",
    "     ELSE CASE WHEN bgVal <=250 THEN 'in_range'  \n",
    "          ELSE CASE WHEN bgVal >250 THEN 'above' \n",
    "          END \n",
    "     END\n",
    "END AS 'bin'\n",
    "FROM bgTable\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the query, we'll apply it to bgTable. This will add an extra column ('bin') for the bin each row belongs to ('below','in_range', and 'above'). Again, we'll perform this operation in chunks (since we're assuming that the table is too large to load into memory). \n",
    "\n",
    "The code in the next cell does the following: 1) loads a chunk of our table from our database 3 rows at a time, 2) performs the 'binItems' query on each chunk and 3) appends the resulting chunks to a new table called 'bgTableBinned' that has a new 'bin' column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for query_chunk in pd.read_sql_query(binItems, con, chunksize=3):\n",
    "    query_chunk.to_sql('bgTableBinned',con, index= False, if_exists= 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save and close connection to database\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bgVal</th>\n",
       "      <th>time</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>15:52</td>\n",
       "      <td>in_range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>19:22</td>\n",
       "      <td>below</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>347</td>\n",
       "      <td>8:13</td>\n",
       "      <td>above</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bgVal   time       bin\n",
       "0   1    230  15:52  in_range\n",
       "1   2     80  19:22     below\n",
       "2   3    347   8:13     above"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reopen connection and read new table\n",
    "\n",
    "#Connect to our database with new table\n",
    "conNew= sqlite3.connect('bgTable.db')\n",
    "\n",
    "#Read the first few lines from our new table\n",
    "newTable= pd.read_sql_query('SELECT * FROM bgTableBinned LIMIT 3', conNew)\n",
    "newTable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conNew.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note: For some reason, when I run cell #4 the first time, I get a logic error that says database doesn't exist. However, when I run the same cell again, it works, as do the remaining cells. I'll need to explore this a little further tomorrow (maybe I need to create the new table out of the loop first?), but it looks like for the first run, my workflow is doing what I need it to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffering with a CSV file and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a csv file of the data in bgTable in order to perform the same operations with this file format. I could so something similar to what I did with the db file using pandas, but I'll start by avoiding external modules.\n",
    "\n",
    "The key argument that we'll use is the 'buffering' argument for the 'open' function. Before that though, let's define the function that will bin the values into our three bins once more and test the operations on a separate table before we insert it into the chunk loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bgVal</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>15:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>19:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>347</td>\n",
       "      <td>8:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  bgVal   time\n",
       "0   1    230  15:52\n",
       "1   2     80  19:22\n",
       "2   3    347   8:13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's try operating on the sample table from the first line in our notebook\n",
    "table0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 230, u'15:52'],\n",
       "       [2, 80, u'19:22'],\n",
       "       [3, 347, u'8:13']], dtype=object)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We'll need to import numpy and turn this dataframe into an array\n",
    "#Let's verify that we have a three column array\n",
    "import numpy as np\n",
    "\n",
    "arrayTable= np.array(table0)\n",
    "arrayTable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binFxn(myArray):\n",
    "    '''This function will be passed and applied to every row in \n",
    "    my chunk (to avoid iterating through a for loop) and will\n",
    "    create create a new column that labels a row based on the\n",
    "    value in its second column as below, in_range, or above'''\n",
    "    if  myArray[1] <= 80: \n",
    "        return 'below'\n",
    "    elif myArray[1] <= 250 and myArray[1] > 80:\n",
    "        return 'in_range'\n",
    "    elif myArray[1] >= 250:\n",
    "        return 'above'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We'll apply the binFxn to each row in our table and \n",
    "#the output will be a new column that we'll call newArray\n",
    "newArray= np.apply_along_axis(binFxn, 1, arrayTable)\n",
    "newArray= newArray.reshape(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 230, u'15:52', 'in_range'],\n",
       "       [2, 80, u'19:22', 'below'],\n",
       "       [3, 347, u'8:13', 'above']], dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We'll append this new array to our origina array\n",
    "#that should give us a 4 column table\n",
    "np.append(arrayTable, newArray, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Seems to be doing what we want it to do. Now we just need to perform this action on every chunk, and then write/append that to a new file. Let's try implementing that on a version of bgTable that comes in csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axis must be less than arr.ndim; axis=1, rank=0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-5e1ec44e41a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmyFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0marrayTable\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mnewArray\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinFxn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrayTable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mnewArray\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnewArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/numpy/lib/shape_base.pyc\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         raise ValueError(\"axis must be less than arr.ndim; axis=%d, rank=%d.\"\n\u001b[0;32m---> 83\u001b[0;31m             % (axis, nd))\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axis must be less than arr.ndim; axis=1, rank=0."
     ]
    }
   ],
   "source": [
    "#Initialize new file to append the new table data into\n",
    "newTable= open('bgTableNew.csv','a')\n",
    "\n",
    "#We'll use the buffering argument to limit the chunk size\n",
    "#buffering=1 mb is the smallest unit we can choose\n",
    "with open('bgTable.csv', buffering=1) as myFile:\n",
    "    for chunk in myFile:\n",
    "        arrayTable= np.array(chunk)\n",
    "        newArray= np.apply_along_axis(binFxn, 1, arrayTable)\n",
    "        newArray= newArray.reshape(3,1)\n",
    "        \n",
    "        newTable.write(np.append(arrayTable, newArray, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will work on this and previous day's method more tomorrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
